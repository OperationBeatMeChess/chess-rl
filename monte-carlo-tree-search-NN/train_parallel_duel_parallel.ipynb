{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "\n",
    "import wandb\n",
    "\n",
    "from torch.multiprocessing import Pool, set_start_method, Lock, Process\n",
    "\n",
    "from parallel import run_games_continuously, torch_safesave, ReplayBufferManager, ChessReplayDataset, duel, run_training_epoch\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/kage/chess_workspace/chess-utils')\n",
    "from utils import RunningAverage\n",
    "from chess_dataset import ChessDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'best_baseSwinChessNet.pt'\n",
    "BESTMODEL_PATH = 'bestMCTS' + MODEL_PATH\n",
    "CURRMODEL_PATH = 'currentMCTS' + MODEL_PATH\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "DATASET_SIZE = 25_000\n",
    "BUFFER_SIZE = 50_000\n",
    "\n",
    "TRAIN_EVERY = 30\n",
    "TRAIN_EPOCHS = 4\n",
    "SELFPLAY_SIMS = 700\n",
    "BATCH_SIZE = 96\n",
    "DUEL_ROUNDS = 7\n",
    "DUEL_WINRATE = 0.55\n",
    "DUEL_SIMS = 100\n",
    "DUEL_PROCESSES = 4\n",
    "NUM_GAMES = 1000\n",
    "GAMES_IN_PARALLEL = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_duel(selfplay_buffer_proxy, expert_dataset, file_lock):\n",
    "    \"\"\" \n",
    "    Train on selfplay and expert data. Builds a dataset of size dataset_size, where the\n",
    "    proportion of data comes from,\n",
    "    \n",
    "        expert_size + selfplay_size = dataset_size \n",
    "    \n",
    "    If the replay buffer has more data than dataset_size, will sample from selfplay data only\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize buffer dataset\n",
    "    selfplay_dataset = ChessReplayDataset(selfplay_buffer_proxy)\n",
    "    \n",
    "    curr_best_wins = 0 \n",
    "    curr_best_score = 0\n",
    "    tmp_best_model_state = None\n",
    "\n",
    "    bestmodel_path = BESTMODEL_PATH if os.path.exists(BESTMODEL_PATH) else MODEL_PATH\n",
    "\n",
    "    for i in range(TRAIN_EPOCHS):\n",
    "        # Do training in a separate process\n",
    "        with Pool(1) as pool:\n",
    "            stats = pool.apply(run_training_epoch, (CURRMODEL_PATH, selfplay_dataset, expert_dataset, DATASET_SIZE))\n",
    "\n",
    "        duel_score_dict = duel(CURRMODEL_PATH, bestmodel_path, DUEL_ROUNDS, file_lock, num_sims=DUEL_SIMS, num_processes=DUEL_PROCESSES) # CURRMODEL_PATH exists after run_training_epoch\n",
    "        \n",
    "        print(f\"Duel scoring: {duel_score_dict}\")\n",
    "        wandb.log(duel_score_dict)\n",
    "        \n",
    "        if duel_score_dict['score'] > (DUEL_WINRATE * 2 * DUEL_ROUNDS): \n",
    "            print(\"MODEL WON!\")\n",
    "            if duel_score_dict['score'] > curr_best_score:\n",
    "                curr_best_score = duel_score_dict['score']\n",
    "                curr_best_wins = duel_score_dict['wins']\n",
    "                tmp_best_model_state = torch.load(CURRMODEL_PATH)\n",
    "            elif duel_score_dict['score'] == curr_best_score and duel_score_dict['wins'] > curr_best_wins:\n",
    "                curr_best_wins = duel_score_dict['wins']\n",
    "                tmp_best_model_state = torch.load(CURRMODEL_PATH)\n",
    "                    \n",
    "        print(f\"Epoch - Loss: {stats.get_average('loss')} - Ploss: {stats.get_average('policy_loss')} - Vloss {stats.get_average('value_loss')}\")\n",
    "        wandb.log({\"epoch_loss\":  stats.get_average('loss'),\n",
    "                   \"epoch_ploss\": stats.get_average('policy_loss'),\n",
    "                   \"epoch_vloss\": stats.get_average('value_loss')})\n",
    "    \n",
    "    # Save model if new best and clear buffer\n",
    "    if tmp_best_model_state is not None:\n",
    "        torch.save(tmp_best_model_state, BESTMODEL_PATH)\n",
    "        selfplay_buffer_proxy.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_bufferproxy(buffer_proxy):\n",
    "    shared_buffer_state = buffer_proxy.get_state()\n",
    "    with open('replay_buffer_state.pkl', 'wb') as f:\n",
    "        pickle.dump(shared_buffer_state, f)\n",
    "\n",
    "        \n",
    "def run_training(num_games, expert_dataset):\n",
    "    # with open('replay_buffer_state.pkl', 'rb') as f:\n",
    "    #     buffer_state = pickle.load(f)\n",
    "\n",
    "    # Multiprocessing stuff\n",
    "    manager = ReplayBufferManager()\n",
    "    manager.start()\n",
    "    shared_replay_buffer = manager.ReplayBuffer(capacity=BUFFER_SIZE)\n",
    "    # shared_replay_buffer.from_dict(buffer_state)\n",
    "    shutdown_event = manager.Event()\n",
    "    buffer_lock = manager.Lock()\n",
    "    global_game_counter = manager.GameCounter()\n",
    "    file_lock = Lock()\n",
    "    \n",
    "    # Load initial model for self-play process\n",
    "    model_state = torch.load(MODEL_PATH)\n",
    "    model_state = {k: v.cpu() for k, v in model_state.items()} # can't share cuda tensors\n",
    "\n",
    "    # Save current model so training and dueling processes can load/use it \n",
    "    # torch.save(model_state, CURRMODEL_PATH)\n",
    "\n",
    "    # Start the continuous game running in a separate process\n",
    "    process = Process(target=run_games_continuously, args=(model_state, BESTMODEL_PATH, shared_replay_buffer, GAMES_IN_PARALLEL, buffer_lock, file_lock, global_game_counter, shutdown_event))\n",
    "    process.start()\n",
    "\n",
    "    next_train = TRAIN_EVERY\n",
    "\n",
    "    # Main training loop\n",
    "    training = True\n",
    "    while training:\n",
    "        game_count = global_game_counter.count\n",
    "        \n",
    "        if game_count >= num_games:\n",
    "            shutdown_event.set()\n",
    "            training = False\n",
    "            \n",
    "        if game_count >= next_train:\n",
    "            # Finish current games before updating/dueling\n",
    "            print(\"Waiting for games to finish...\")\n",
    "            shutdown_event.set()\n",
    "            process.join()\n",
    "            shutdown_event.clear()\n",
    "            print(\"All done. Saving buffer and starting training...\")\n",
    "\n",
    "            # Save buffer, train, duel\n",
    "            pickle_bufferproxy(shared_replay_buffer)\n",
    "            update_and_duel(shared_replay_buffer, expert_dataset, file_lock)\n",
    "            \n",
    "            next_train += TRAIN_EVERY\n",
    "\n",
    "            # Restart background process\n",
    "            print(\"Restarting self-play process...\")\n",
    "            process = Process(target=run_games_continuously, args=(model_state, BESTMODEL_PATH, shared_replay_buffer, GAMES_IN_PARALLEL, buffer_lock, file_lock, global_game_counter, shutdown_event))\n",
    "            process.start()\n",
    "\n",
    "    process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PGN_FILE = \"/home/kage/chess_workspace/cclr/COMBINED_ccrltest.pgn\"\n",
    "# PGN_FILE = \"/home/kage/chess_workspace/TCEC_Cup_1_Final_5.pgn\"\n",
    " \n",
    "# Load the datasets\n",
    "expert_dataset = ChessDataset([PGN_FILE])\n",
    "print(len(expert_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"Chess\")\n",
    "set_start_method('spawn', force=True)\n",
    "\n",
    "run_training(NUM_GAMES, expert_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
