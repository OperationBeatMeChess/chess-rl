{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS Training Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kage/chess_workspace/chess_venv311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os, pickle, random\n",
    "\n",
    "import wandb\n",
    "\n",
    "import gym\n",
    "import chess\n",
    "from torch.multiprocessing import Pool, set_start_method, Lock, Process\n",
    "\n",
    "import adversarial_gym\n",
    "from OBM_ChessNetwork import ChessNetworkSimple\n",
    "from search import MonteCarloTreeSearch\n",
    "from parallel import run_games_continuously, torch_safesave, ReplayBufferManager, ChessReplayDataset, duel, run_training_epoch\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/kage/chess_workspace/chess_utils')\n",
    "from utils import RunningAverage\n",
    "from chess_dataset import ChessDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'best_baseSwinChessNet.pt'\n",
    "BESTMODEL_PATH = 'bestMCTS' + MODEL_PATH\n",
    "CURRMODEL_PATH = 'currentMCTS' + MODEL_PATH\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "TRAIN_EPOCHS = 5\n",
    "DUEL_ROUNDS = 11\n",
    "\n",
    "NUM_GAMES = 500\n",
    "GAMES_IN_PARALLEL = 9\n",
    "\n",
    "# model = Chess42069NetworkSimple(hidden_dim=512, device=DEVICE, base_lr=0.1)\n",
    "# best_model = Chess42069NetworkSimple(hidden_dim=512, device=DEVICE)\n",
    "\n",
    "# if MODEL_PATH is not None:\n",
    "#     model.load_state_dict(torch.load(MODEL_PATH))\n",
    "#     best_model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "# model = torch.compile(model)\n",
    "# best_model = torch.compile(best_model)\n",
    "# best_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_duel(selfplay_buffer_proxy, expert_dataset, file_lock, dataset_size = 25_000,\n",
    "                epochs = 5, duel_rounds = 11, duel_winrate = 0.55):\n",
    "    \"\"\" \n",
    "    Train on selfplay and expert data. Builds a dataset of size dataset_size, where the\n",
    "    proportion of data comes from,\n",
    "    \n",
    "        expert_size + selfplay_size = dataset_size \n",
    "    \n",
    "    If the replay buffer has more data than dataset_size, will sample from selfplay data only\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize buffer dataset\n",
    "    selfplay_dataset = ChessReplayDataset(selfplay_buffer_proxy)\n",
    "    \n",
    "    curr_best_wins = 0 \n",
    "    curr_best_score = 0\n",
    "    tmp_best_model_state = None\n",
    "\n",
    "    bestmodel_path = BESTMODEL_PATH if os.path.exists(BESTMODEL_PATH) else MODEL_PATH\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Do training in a separate process\n",
    "        with Pool(1) as pool:\n",
    "            stats = pool.apply(run_training_epoch, (CURRMODEL_PATH, selfplay_dataset, expert_dataset, dataset_size))\n",
    "\n",
    "        duel_score_dict = duel(CURRMODEL_PATH, bestmodel_path, duel_rounds, file_lock, num_sims=100, num_processes=5) # CURRMODEL_PATH exists after run_training_epoch\n",
    "        \n",
    "        print(f\"Duel scoring: {duel_score_dict}\")\n",
    "        wandb.log(duel_score_dict)\n",
    "        \n",
    "        if duel_score_dict['score'] > (duel_winrate * 2 * duel_rounds): \n",
    "            print(\"MODEL WON!\")\n",
    "            if duel_score_dict['score'] > curr_best_score:\n",
    "                curr_best_score = duel_score_dict['score']\n",
    "                curr_best_wins = duel_score_dict['wins']\n",
    "                tmp_best_model_state = torch.load(CURRMODEL_PATH)\n",
    "            elif duel_score_dict['score'] == curr_best_score and duel_score_dict['wins'] > curr_best_wins:\n",
    "                curr_best_wins = duel_score_dict['wins']\n",
    "                tmp_best_model_state = torch.load(CURRMODEL_PATH)\n",
    "                    \n",
    "        print(f\"Epoch - Loss: {stats.get_average('loss')} - Ploss: {stats.get_average('policy_loss')} - Vloss {stats.get_average('value_loss')}\")\n",
    "        wandb.log({\"epoch_loss\":  stats.get_average('loss'),\n",
    "                   \"epoch_ploss\": stats.get_average('policy_loss'),\n",
    "                   \"epoch_vloss\": stats.get_average('value_loss')})\n",
    "    \n",
    "    # Save model if new best and clear buffer\n",
    "    if tmp_best_model_state is not None:\n",
    "        torch.save(tmp_best_model_state, BESTMODEL_PATH)\n",
    "        selfplay_buffer_proxy.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_bufferproxy(buffer_proxy):\n",
    "    shared_buffer_state = buffer_proxy.get_state()\n",
    "    with open('replay_buffer_state.pkl', 'wb') as f:\n",
    "        pickle.dump(shared_buffer_state, f)\n",
    "\n",
    "        \n",
    "def run_training(num_games, expert_dataset, games_in_parallel, train_every, duel_winrate=0.55, buffer_capacity=50_000):\n",
    "    # with open('replay_buffer_state.pkl', 'rb') as f:\n",
    "    #     buffer_state = pickle.load(f)\n",
    "\n",
    "    # Multiprocessing stuff\n",
    "    manager = ReplayBufferManager()\n",
    "    manager.start()\n",
    "    shared_replay_buffer = manager.ReplayBuffer(capacity=buffer_capacity)\n",
    "    # shared_replay_buffer.from_dict(buffer_state)\n",
    "    shutdown_event = manager.Event()\n",
    "    buffer_lock = manager.Lock()\n",
    "    global_game_counter = manager.GameCounter()  # Initialize a shared counter\n",
    "    file_lock = Lock()\n",
    "    \n",
    "    # Load initial model for self-play process\n",
    "    model_state = torch.load(MODEL_PATH)\n",
    "    model_state = {k: v.cpu() for k, v in model_state.items()} # can't share cuda tensors\n",
    "\n",
    "    # Save current model so training and dueling processes can load/use it \n",
    "    torch.save(model_state, CURRMODEL_PATH)\n",
    "\n",
    "    # Start the continuous game running in a separate process\n",
    "    process = Process(target=run_games_continuously, args=(model_state, BESTMODEL_PATH, shared_replay_buffer, games_in_parallel, buffer_lock, file_lock, global_game_counter, shutdown_event))\n",
    "    process.start()\n",
    "\n",
    "    next_train = train_every\n",
    "\n",
    "    # Main training loop\n",
    "    training = True\n",
    "    while training:\n",
    "        game_count = global_game_counter.count\n",
    "        \n",
    "        if game_count >= num_games:\n",
    "            shutdown_event.set()\n",
    "            training = False\n",
    "            \n",
    "        if game_count >= next_train:\n",
    "            # Finish current games before updating/dueling\n",
    "            print(\"Waiting for games to finish...\")\n",
    "            shutdown_event.set()\n",
    "            process.join()\n",
    "            shutdown_event.clear()\n",
    "            print(\"All done. Starting training...\")\n",
    "\n",
    "            update_and_duel(shared_replay_buffer, expert_dataset, file_lock, dataset_size=25_000,\n",
    "                            epochs=5, duel_winrate=duel_winrate, duel_rounds=7)\n",
    "            next_train += train_every\n",
    "\n",
    "            # Restart background process\n",
    "            print(\"Restarting self-play process...\")\n",
    "            process = Process(target=run_games_continuously, args=(model_state, BESTMODEL_PATH, shared_replay_buffer, games_in_parallel, buffer_lock, file_lock, global_game_counter, shutdown_event))\n",
    "            process.start()\n",
    "\n",
    "    process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/kage/chess_workspace/COMBINED_tcec+alphazero.pgn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/train_parallel_duel_parallel.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/train_parallel_duel_parallel.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m PGN_FILE \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/kage/chess_workspace/COMBINED_tcec+alphazero.pgn\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/train_parallel_duel_parallel.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# PGN_FILE = \"/home/kage/chess_workspace/PGN-data/tcec+alphastock/TCEC_Cup_1_Final_5.pgn\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/train_parallel_duel_parallel.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/train_parallel_duel_parallel.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Load the datasets\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/train_parallel_duel_parallel.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m expert_dataset \u001b[39m=\u001b[39m ChessDataset(PGN_FILE)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/train_parallel_duel_parallel.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(expert_dataset))\n",
      "File \u001b[0;32m~/chess_workspace/chess_utils/chess_dataset.py:14\u001b[0m, in \u001b[0;36mChessDataset.__init__\u001b[0;34m(self, pgn_file)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, pgn_file):\n\u001b[1;32m     13\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpgn_file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(pgn_file)\n\u001b[1;32m     15\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate_pgn_data()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/kage/chess_workspace/COMBINED_tcec+alphazero.pgn'"
     ]
    }
   ],
   "source": [
    "PGN_FILE = \"/home/kage/chess_workspace/PGN-data/tcec+alphastock/COMBINED_tcec+alphazero.pgn\"\n",
    "# PGN_FILE = \"/home/kage/chess_workspace/PGN-data/tcec+alphastock/TCEC_Cup_1_Final_5.pgn\"\n",
    "\n",
    "# Load the datasets\n",
    "expert_dataset = ChessDataset(PGN_FILE)\n",
    "print(len(expert_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"Chess\")\n",
    "set_start_method('spawn', force=True)\n",
    "\n",
    "\n",
    "run_training(NUM_GAMES, expert_dataset, GAMES_IN_PARALLEL, train_every=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
