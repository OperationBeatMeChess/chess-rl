{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kage/chess_workspace/chess_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time, os, random\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "\n",
    "import wandb\n",
    "\n",
    "import chess\n",
    "import chess.pgn\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from chess_transformer.superChessNet import SuperChessNetwork\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../chess-utils')\n",
    "from chess_dataset import ChessDataset\n",
    "from utils import RunningAverage\n",
    "from adversarial_gym.chess_env import ChessEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PGN_DIR_TRAIN = '/home/kage/chess_workspace/ALL_PGN_FILES'\n",
    "PGN_DIR_TEST = '/home/kage/chess_workspace/ccrl/test'\n",
    "# PGN_DIR_TRAIN = '/home/kage/chess_workspace/tmp'\n",
    "# PGN_DIR_TEST = '/home/kage/chess_workspace/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kage/chess_workspace/chess_env/lib/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "def align_state_dict_keys(state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for key, value in state_dict.items():\n",
    "        # Remove the unexpected prefix from each key\n",
    "        new_key = re.sub(r'^od\\.|^_orig_mod\\.', '', key)\n",
    "        new_state_dict[new_key] = value\n",
    "    return new_state_dict\n",
    "\n",
    "def get_backbone_dict(state_dict):\n",
    "    backbone_dict = OrderedDict()\n",
    "    for key, value in state_dict.items():\n",
    "        if key.startswith('swin_transformer'):\n",
    "            backbone_dict[key] = value\n",
    "    return backbone_dict\n",
    "\n",
    "def load_backbone(model, pretrained_path):\n",
    "    pretrained_dict = align_state_dict_keys(torch.load(pretrained_path))\n",
    "    backbone_dict = get_backbone_dict(pretrained_dict)\n",
    "    model.load_state_dict(backbone_dict, strict=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "MODEL_PATH = 'super-baseSwinChessNet.pt'\n",
    "MODEL_PRETRAIN_PATH = '/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/best_1024-baseSwinChessNet.pt'\n",
    "MODEL_SAVEPATH = \"super-baseSwinChessNet.pt\"\n",
    "\n",
    "model = SuperChessNetwork(memory_size=8500, topk=750, base_lr=0.2, device='cuda')\n",
    "# if os.path.exists(MODEL_PATH):\n",
    "#     print(f\"Loading model at: {MODEL_PATH}\")\n",
    "#     model.load_state_dict(align_state_dict_keys(torch.load(MODEL_PATH)))\n",
    "\n",
    "# # Load backbone\n",
    "# model = load_backbone(model, MODEL_PRETRAIN_PATH)\n",
    "\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation(model, val_loader, stats):\n",
    "    model.eval()\n",
    "    stats.reset([\"val_loss\", \"val_ploss\", \"val_vloss\", \"val_hvloss\", \"val_mvloss\"])\n",
    "    t1 = time.perf_counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (state, action, result) in enumerate(val_loader):\n",
    "            state = state.float().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            action = action.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            result = result.float().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            \n",
    "            policy_output, hvalue_output, value_output, features = model(state.unsqueeze(1))\n",
    "            \n",
    "            # mem_policy_loss, mem_value_loss = model.memory_loss(features[1], features[2], action, result)\n",
    "            mem_value_loss = model.value_loss(features[2].squeeze(), result)\n",
    "            head_value_loss = model.value_loss(hvalue_output.squeeze(), result)\n",
    "            \n",
    "            policy_loss = model.policy_loss(policy_output.squeeze(), action)\n",
    "            value_loss = model.value_loss(value_output.squeeze(), result)\n",
    "            \n",
    "            loss = policy_loss + value_loss + head_value_loss + mem_value_loss\n",
    "\n",
    "            stats.update({\n",
    "                \"val_loss\": loss.detach().item(),\n",
    "                \"val_ploss\": policy_loss.detach().item(),\n",
    "                \"val_vloss\": value_loss.detach().item(),\n",
    "                \"val_hvloss\": head_value_loss.detach().item(),\n",
    "                \"val_mvloss\": mem_value_loss.detach().item()\n",
    "            })\n",
    "        \n",
    "    return stats.get_average('val_loss'), stats.get_average('val_ploss'), stats.get_average('val_vloss'), stats.get_average('val_mem_vloss'), stats.get_average('val_hvloss')\n",
    "\n",
    "def training_round(model, train_loader, val_loader, num_epochs=10, log_every=1000, validation_every=20_000):\n",
    "    stats = RunningAverage()\n",
    "    stats.add([\"train_loss\", \"train_vloss\",\n",
    "               \"train_hvloss\", \"train_ploss\",\n",
    "               \"train_mvloss\", \"val_loss\",\n",
    "               \"val_vloss\", \"val_hvloss\",\n",
    "               \"val_ploss\", \"val_mvloss\"])\n",
    "\n",
    "    best_val_loss = 1000\n",
    "    \n",
    "    for epoch in range(num_epochs): \n",
    "        model.train()\n",
    "        t1 = time.perf_counter()\n",
    "        \n",
    "        for i, (state, action, result) in enumerate(train_loader):\n",
    "            state = state.float().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            action = action.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            result = result.float().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            \n",
    "            model.optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                policy_output, valueh_output, value_output, features = model(state.unsqueeze(1)) # features: [states, mem_actions, mem_result]\n",
    "           \n",
    "                # mem_policy_loss, mem_value_loss = model.memory_loss(features[1], features[2], action, result)\n",
    "                mem_value_loss = model.value_loss(features[2].squeeze(), result)\n",
    "                head_value_loss = model.value_loss(valueh_output.squeeze(), result)     \n",
    "\n",
    "                policy_loss = model.policy_loss(policy_output, action)\n",
    "                value_loss = model.value_loss(value_output.squeeze(), result)\n",
    "\n",
    "                loss = policy_loss + value_loss + mem_value_loss + head_value_loss\n",
    "            \n",
    "            # AMP with gradient clipping\n",
    "            model.grad_scaler.scale(loss).backward()\n",
    "            model.grad_scaler.unscale_(model.optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            model.grad_scaler.step(model.optimizer)\n",
    "            scale = model.grad_scaler.get_scale()\n",
    "            model.grad_scaler.update()\n",
    "\n",
    "            skip_lr_sched = scale > model.grad_scaler.get_scale()\n",
    "            \n",
    "            if not skip_lr_sched: model.scheduler.step()\n",
    "\n",
    "            # Write data to memory\n",
    "            model.write_to_memory(features[0], action, result)\n",
    "\n",
    "            stats.update({\n",
    "                \"train_loss\": loss.item(),\n",
    "                \"train_vloss\": value_loss.item(),\n",
    "                \"train_ploss\": policy_loss.item(),\n",
    "                \"train_hvloss\": head_value_loss.item(),\n",
    "                \"train_mvloss\": mem_value_loss.item(),\n",
    "            })\n",
    "            \n",
    "            if i % log_every == 0:\n",
    "                wandb.log({\"lr\": model.scheduler.get_last_lr()[0],\n",
    "                            \"train_loss\": stats.get_average('train_loss'),\n",
    "                            \"train_vloss\": stats.get_average('train_vloss'),\n",
    "                            \"train_ploss\": stats.get_average('train_ploss'),\n",
    "                            \"train_hvloss\": stats.get_average('train_hvloss'),\n",
    "                            \"train_mvloss\": stats.get_average('train_mvloss'),\n",
    "                            \"iter\": i})\n",
    "            \n",
    "            if i % validation_every == 0 and i > 0 :\n",
    "                val_loss, val_ploss, val_vloss, val_mem_vloss, val_hvloss = run_validation(model, val_loader, stats)\n",
    "                \n",
    "                wandb.log({\"val_loss\": val_loss,\n",
    "                           \"val_vloss\": val_vloss,\n",
    "                           \"val_ploss\": val_ploss,\n",
    "                           \"val_hvloss\": val_hvloss,\n",
    "                           \"val_mvloss\": val_mem_vloss,\n",
    "                           \"iter\": i})\n",
    "\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    torch.save(model.state_dict(), \"best_\" + MODEL_SAVEPATH)\n",
    "\n",
    "        print(f\"Epoch took {time.perf_counter()-t1} seconds \")\n",
    "        torch.save(model.state_dict(), MODEL_SAVEPATH)\n",
    "\n",
    "def run_training(num_rounds):\n",
    "    train_data = [pgn.path for pgn in os.scandir(PGN_DIR_TRAIN) if pgn.name.endswith(\".pgn\")]\n",
    "    test_data = [pgn.path for pgn in os.scandir(PGN_DIR_TEST) if pgn.name.endswith(\".pgn\")]\n",
    "\n",
    "    init_dataset = random.sample(train_data, 2)\n",
    "    init_dataset = ChessDataset(init_dataset)\n",
    "    init_loader = DataLoader(init_dataset, batch_size=10, shuffle=True, num_workers=0)\n",
    "    model.initialize_memory(init_loader)\n",
    "\n",
    "    print(f\"Successfully initialized memory\")\n",
    "    for round in range(num_rounds):\n",
    "        print(f\"Starting round {round}\")\n",
    "        # build dataset \n",
    "        # randomly sample dataset_size pgn files \n",
    "        sampled_train_data = random.sample(train_data, DATASET_SIZE_TRAIN)\n",
    "        sampled_test_data = random.sample(test_data, DATASET_SIZE_TEST)\n",
    "\n",
    "        train_dataset = ChessDataset(sampled_train_data)\n",
    "        test_dataset = ChessDataset(sampled_test_data)\n",
    "        \n",
    "        print(f\"Successfully loaded dataset with {len(train_dataset)} / {len(test_dataset)} images\")\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=48, shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(test_dataset, batch_size=48, shuffle=False, num_workers=0)   \n",
    "\n",
    "        training_round(model, train_loader, val_loader, num_epochs=3, log_every=1000, validation_every=20_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkeithg33\u001b[0m (\u001b[33mopen_sim2real\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/wandb/run-20231211_223125-mzwc0ucb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/open_sim2real/Chess/runs/mzwc0ucb' target=\"_blank\">legendary-yogurt-361</a></strong> to <a href='https://wandb.ai/open_sim2real/Chess' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/open_sim2real/Chess' target=\"_blank\">https://wandb.ai/open_sim2real/Chess</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/open_sim2real/Chess/runs/mzwc0ucb' target=\"_blank\">https://wandb.ai/open_sim2real/Chess/runs/mzwc0ucb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized memory\n",
      "Starting round 0\n",
      "Successfully loaded dataset with 4446043 / 292714 images\n",
      "Variable val_mem_ploss is not being tracked.\n",
      "Variable val_mem_vloss is not being tracked.\n",
      "Variable val_mem_ploss is not being tracked.\n",
      "Variable val_mem_vloss is not being tracked.\n",
      "Variable val_mem_ploss is not being tracked.\n",
      "Variable val_mem_vloss is not being tracked.\n",
      "Variable val_mem_ploss is not being tracked.\n",
      "Variable val_mem_vloss is not being tracked.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m DATASET_SIZE_TEST \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# DATASET_SIZE_TRAIN = 1\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# DATASET_SIZE_TEST = 1\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m run_training(NUM_ROUNDS)\n",
      "\u001b[1;32m/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m48\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m48\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)   \n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m training_round(model, train_loader, val_loader, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, log_every\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, validation_every\u001b[39m=\u001b[39;49m\u001b[39m20_000\u001b[39;49m)\n",
      "\u001b[1;32m/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     loss \u001b[39m=\u001b[39m policy_loss \u001b[39m+\u001b[39m value_loss \u001b[39m# + mem_policy_loss \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# AMP with gradient clipping\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m model\u001b[39m.\u001b[39;49mgrad_scaler\u001b[39m.\u001b[39;49mscale(loss)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m model\u001b[39m.\u001b[39mgrad_scaler\u001b[39m.\u001b[39munscale_(model\u001b[39m.\u001b[39moptimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), max_norm\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/chess_workspace/chess_env/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/chess_workspace/chess_env/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fbe814b1dd0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fbe802b7b50, execution_count=5 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 7fbe31d94ad0, raw_cell=\"wandb.init(project='Chess')\n",
      "\n",
      "NUM_ROUNDS = 50\n",
      "DATAS..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/home/kage/chess_workspace/chess-rl/monte-carlo-tree-search-NN/expert_super-pretraining.ipynb#X12sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "wandb.init(project='Chess')\n",
    "\n",
    "NUM_ROUNDS = 50\n",
    "DATASET_SIZE_TRAIN = 10\n",
    "DATASET_SIZE_TEST = 1\n",
    "# DATASET_SIZE_TRAIN = 1\n",
    "# DATASET_SIZE_TEST = 1\n",
    "run_training(NUM_ROUNDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
