{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chess RL + Expert Learning + Weirdness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kage/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import chess\n",
    "import gym\n",
    "import chess\n",
    "import os, sys, copy\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import adversarial_gym\n",
    "from adversarial_gym.chess_env import ChessEnv\n",
    "\n",
    "from OBM_ChessNetwork import Chess42069NetworkSimple\n",
    "\n",
    "sys.path.append('../../chess_utils')\n",
    "from chess_dataset import ChessDataset\n",
    "from utils import RunningAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Gameplay Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(env, white, black, perspective=None, sample_n=1, duel=False):\n",
    "    step = 0\n",
    "    actions = []\n",
    "    log_probs = []\n",
    "    observations = []\n",
    "    values = []\n",
    "    done = False\n",
    "    obs = env.reset()[0]\n",
    "    while not done:\n",
    "        # Note: Modify the get_action function to return the action, log_prob, and state value\n",
    "        if step % 2 == 0:\n",
    "            action_logits, value_estimate = white(obs[0])\n",
    "            action, log_prob = white.to_action(action_logits, env.board.legal_moves, sample_n) # same for black/white\n",
    "        else:\n",
    "            action_logits, value_estimate = black(obs[0])\n",
    "            value_estimate = -value_estimate if perspective is None else value_estimate\n",
    "            action, log_prob = black.to_action(action_logits, env.board.legal_moves, sample_n) # same for black/white\n",
    "\n",
    "        if perspective is None or perspective == chess.WHITE and step % 2 == 0 or perspective == chess.BLACK and step % 2 == 1:\n",
    "            observations.append(obs[0])\n",
    "            actions.append(action)\n",
    "            log_probs.append(log_prob)\n",
    "            values.append(value_estimate)\n",
    "\n",
    "\n",
    "        obs, reward, done, _, info = env.step(action)\n",
    "        step += 1\n",
    "        \n",
    "    if reward in [-1,1]:\n",
    "        print(f\"PERSPECTIVE: {perspective} - GAME OUTCOME: {reward}\")\n",
    "    else:\n",
    "        print(f\"DRAW\")\n",
    "\n",
    "    # Reward is 1 if chosen perspective won and -1 if chosen perspective lost\n",
    "    # If dueling set reward to 1 for a win and zero otherwise\n",
    "    if perspective is not None:\n",
    "        if perspective == chess.BLACK: reward *= -1 \n",
    "        if duel and reward != 1: reward = 0\n",
    "\n",
    "    rewards = prepare_game_rewards(reward, perspective, len(actions)) if not duel else reward\n",
    "\n",
    "    return observations, actions, log_probs, values, rewards\n",
    "\n",
    "\n",
    "def prepare_game_rewards(reward, perspective, game_len):\n",
    "    if perspective is not None:\n",
    "        # Reward in [-1, 0, 1] \n",
    "        rewards = [reward for _ in range(game_len)]\n",
    "        return rewards\n",
    "    \n",
    "    # Self play alternates +/- reward\n",
    "    # Reward in [-1,0,1].\n",
    "    rewards = [reward if i % 2 == 0 else -reward for i in range(game_len)]\n",
    "\n",
    "    rewards = compute_discounted_rewards(rewards)\n",
    "    return rewards\n",
    "    \n",
    "    \n",
    "def compute_discounted_rewards(reward, gamma=0.99):\n",
    "    \"\"\"Compute discounted rewards for a sequence of rewards.\"\"\"\n",
    "    n = len(reward)\n",
    "    discounted_rewards = [0] * n\n",
    "    running_add = 0\n",
    "    for t in reversed(range(n)):\n",
    "        running_add = running_add * gamma + reward[t]\n",
    "        discounted_rewards[t] = running_add\n",
    "    return discounted_rewards\n",
    "\n",
    "\n",
    "def duel(env, old_model, new_model, num_rounds):\n",
    "    \"\"\" Duel against the previous best model and return the win ratio. \"\"\"\n",
    "    new_model.eval()\n",
    "    with torch.no_grad():\n",
    "        wins = 0\n",
    "        for i in range(num_rounds):\n",
    "            _, _, _, _, _, r_w = play_game(env, new_model, old_model, perspective=chess.WHITE, sample_n = 2, duel=True)\n",
    "            _, _, _, _, _, r_b = play_game(env, old_model, new_model, perspective=chess.BLACK, sample_n = 2, duel=True)\n",
    "\n",
    "            wins += r_w + r_b\n",
    "    new_model.train()    \n",
    "    return wins / (2 * num_rounds)\n",
    "\n",
    "\n",
    "def self_play(env, model, num_games):\n",
    "    \"\"\" Plays num_games against itself to gather obs, actions, log_probs, rewards data \"\"\"\n",
    "    # TODO: check if numpy array of shape (num_games, 4) is faster, each row could be output of play_game\n",
    "    actions = []\n",
    "    log_probs = []\n",
    "    rewards = []\n",
    "    observations = []\n",
    "    for _ in range(num_games):\n",
    "        g_obs, g_actions, g_log_probs, g_reward = play_game(env, model, model, perspective=None)\n",
    "        actions.append(g_actions)\n",
    "        log_probs.append(g_log_probs)\n",
    "        rewards.append(g_reward)\n",
    "        observations.append(g_obs)\n",
    "    return observations, actions, log_probs, rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expert Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation(model, val_loader, stats):\n",
    "    model.eval()\n",
    "    stats.reset(\"val_loss\")\n",
    "    t1 = time.perf_counter()\n",
    "    with torch.no_grad():\n",
    "        for i, (state, action, result) in enumerate(val_loader):\n",
    "            state = state.float().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            action = action.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            result = result.float().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            \n",
    "            policy_output, value_output = model(state.unsqueeze(1))\n",
    "            policy_loss = model.policy_loss(policy_output.squeeze(), action)\n",
    "            value_loss = model.val_loss(value_output.squeeze(), result)\n",
    "            \n",
    "            loss = policy_loss + value_loss\n",
    "            stats.update(\"val_loss\", loss.item())\n",
    "    \n",
    "    print(f\"Mean Validation Loss: {stats.get_average('val_loss')}, time elapsed: {time.perf_counter()-t1} seconds\")\n",
    "    return stats.get_average('val_loss')\n",
    "\n",
    "\n",
    "def expert_study(model, dataset, percent_dataset=0.1):\n",
    "    \"\"\" Trains on TCEC data in a supervised fashion (behaviour cloning)\"\"\"\n",
    "\n",
    "    # Load random subset of dataset and split\n",
    "    study_size = int(percent_dataset * len(dataset))\n",
    "    random_indices = np.random.randint(0, study_size, study_size)\n",
    "    study_dataset = Subset(dataset, random_indices)\n",
    "    \n",
    "    train_ratio = 0.9\n",
    "    train_size = int(train_ratio * study_size)\n",
    "    val_size = study_size - train_size\n",
    "    train_dataset, val_dataset = random_split(study_dataset, [train_size, val_size])\n",
    "\n",
    "    # Create data loaders for the training and validation sets\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, \n",
    "                            pin_memory=False, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, \n",
    "                            pin_memory=False, num_workers=2)\n",
    "\n",
    "    stats = RunningAverage()\n",
    "    stats.add([\"train_loss\", \"val_loss\", \"train_p_loss\", \"train_v_loss\"])\n",
    "\n",
    "    model.train()\n",
    "    t1 = time.perf_counter()\n",
    "    for i, (state, action, result) in enumerate(train_loader):\n",
    "        state = state.float().to(model.device)\n",
    "        action = action.to(model.device)\n",
    "        result = result.float().to(model.device)\n",
    "\n",
    "        with autocast():\n",
    "            policy_output, value_output = model(state.unsqueeze(1))\n",
    "            policy_loss = model.policy_loss(policy_output.squeeze(), action)\n",
    "            value_loss = model.val_loss(value_output.squeeze(), result)\n",
    "            loss = policy_loss + value_loss\n",
    "        \n",
    "        # AMP with gradient clipping\n",
    "        model.optimizer.zero_grad()\n",
    "        model.grad_scaler.scale(loss).backward()\n",
    "        model.grad_scaler.unscale_(model.optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        model.grad_scaler.step(model.optimizer)\n",
    "        model.grad_scaler.update()\n",
    "\n",
    "        stats.update({\n",
    "            \"train_loss\": loss.item(),\n",
    "            \"train_p_loss\": policy_loss.item(),\n",
    "            \"train_v_loss\": value_loss.item()\n",
    "            })\n",
    "        \n",
    "    print(f\"Study Train Loss: {stats.get_average('train_loss')}\")\n",
    "    # wandb.log({\"study_train_loss\": stats.get_average('train_loss')})\n",
    "    t2 = time.perf_counter()\n",
    "    valid_loss = run_validation(model, val_loader, stats)\n",
    "    # wandb.log({\"val_loss\": valid_loss, \"iter\": i})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kage/.local/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model at: {MODEL_PATH}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chess42069NetworkSimple(\n",
       "  (swin_transformer): SwinTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(1, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layers): Sequential(\n",
       "      (0): SwinTransformerStage(\n",
       "        (downsample): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.009)\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (act): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerStage(\n",
       "        (downsample): PatchMerging(\n",
       "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.018)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.027)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): SwinTransformerStage(\n",
       "        (downsample): PatchMerging(\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.036)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.045)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.055)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.064)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.073)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.082)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): SwinTransformerStage(\n",
       "        (downsample): PatchMerging(\n",
       "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.091)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.100)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate=none)\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (head): ClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "      (flatten): Identity()\n",
       "    )\n",
       "  )\n",
       "  (policy_head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "    (2): Linear(in_features=256, out_features=4672, bias=True)\n",
       "  )\n",
       "  (value_head): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (1): RReLU(lower=0.125, upper=0.3333333333333333)\n",
       "    (2): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (3): Tanh()\n",
       "  )\n",
       "  (val_loss): MSELoss()\n",
       "  (policy_loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "MODEL_PATH = '/home/kage/chess_workspace/simpler_SwinChessNet42069.pt'\n",
    "\n",
    "model = Chess42069NetworkSimple(hidden_dim=256, device='cuda')\n",
    "best_model = Chess42069NetworkSimple(hidden_dim=256, device='cuda')\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"Loading model at: {MODEL_PATH}\")\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    best_model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train - VPG with Self-Play and Dueling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kage/.local/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:31: UserWarning: \u001b[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (8, 8)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train Params\n",
    "PGN_FILE = '/home/kage/chess_workspace/PGN-data/alphazero_stockfish_all/alphazero_vs_stockfish_all.pgn'\n",
    "MODEL_SAVEPATH = '/home/kage/chess_workspace/WACKY_RL_MODEL.pt'\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "STUDY_EVERY = 1 \n",
    "DUEL_EVERY = 10\n",
    "\n",
    "chess_dataset = ChessDataset(PGN_FILE)\n",
    "env = gym.make(\"Chess-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "PERSPECTIVE: False - GAME OUTCOME: 1\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "PERSPECTIVE: False - GAME OUTCOME: 1\n",
      "PERSPECTIVE: True - GAME OUTCOME: 1\n",
      "DRAW\n",
      "Model win ratio: 0.05\n",
      "PERSPECTIVE: None - GAME OUTCOME: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [01:21<2:15:16, 81.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [01:43<1:16:06, 46.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [02:02<54:35, 33.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSPECTIVE: None - GAME OUTCOME: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [02:08<36:33, 22.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [02:30<35:47, 22.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [02:48<32:56, 21.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [02:59<27:38, 17.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [03:20<28:52, 18.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [03:33<25:38, 16.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [03:43<22:17, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRAW\n",
      "DRAW\n",
      "DRAW\n",
      "DRAW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [04:07<37:08, 24.76s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(NUM_EPOCHS)):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# # Play games as white or black against the previous best model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[39m# if i % 2 == 0:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m     \u001b[39m# Darwinian duel to the death\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m DUEL_EVERY \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 28\u001b[0m         win_ratio \u001b[39m=\u001b[39m duel(env, best_model, model, num_rounds\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     29\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel win ratio: \u001b[39m\u001b[39m{\u001b[39;00mwin_ratio\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m         \u001b[39mif\u001b[39;00m win_ratio \u001b[39m>\u001b[39m \u001b[39m0.6\u001b[39m:\n",
      "Cell \u001b[0;32mIn[2], line 77\u001b[0m, in \u001b[0;36mduel\u001b[0;34m(env, old_model, new_model, num_rounds)\u001b[0m\n\u001b[1;32m     75\u001b[0m wins \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_rounds):\n\u001b[0;32m---> 77\u001b[0m     _, _, _, _, _, r_w \u001b[39m=\u001b[39m play_game(env, new_model, old_model, perspective\u001b[39m=\u001b[39;49mchess\u001b[39m.\u001b[39;49mWHITE, sample_n \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m, duel\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     78\u001b[0m     _, _, _, _, _, r_b \u001b[39m=\u001b[39m play_game(env, old_model, new_model, perspective\u001b[39m=\u001b[39mchess\u001b[39m.\u001b[39mBLACK, sample_n \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, duel\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     80\u001b[0m     wins \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m r_w \u001b[39m+\u001b[39m r_b\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mplay_game\u001b[0;34m(env, white, black, perspective, sample_n, duel)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[1;32m     11\u001b[0m     \u001b[39m# Note: Modify the get_action function to return the action, log_prob, and state value\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 13\u001b[0m         action_logits, value_estimate \u001b[39m=\u001b[39m white(obs[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     14\u001b[0m         action, log_prob \u001b[39m=\u001b[39m white\u001b[39m.\u001b[39mto_action(action_logits, env\u001b[39m.\u001b[39mboard\u001b[39m.\u001b[39mlegal_moves, sample_n) \u001b[39m# same for black/white\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/chess_workspace/chess-rl/ChessNetwork/OBM_ChessNetwork.py:177\u001b[0m, in \u001b[0;36mChess42069NetworkSimple.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    176\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(x, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 177\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mswin_transformer\u001b[39m.\u001b[39;49mforward_features(x)\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    178\u001b[0m action_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy_head(features)\n\u001b[1;32m    179\u001b[0m board_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue_head(features)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/timm/models/swin_transformer.py:586\u001b[0m, in \u001b[0;36mSwinTransformer.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_features\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    585\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch_embed(x)\n\u001b[0;32m--> 586\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(x)\n\u001b[1;32m    587\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(x)\n\u001b[1;32m    588\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/timm/models/swin_transformer.py:424\u001b[0m, in \u001b[0;36mSwinTransformerStage.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    422\u001b[0m     x \u001b[39m=\u001b[39m checkpoint_seq(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks, x)\n\u001b[1;32m    423\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 424\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblocks(x)\n\u001b[1;32m    425\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/timm/models/swin_transformer.py:292\u001b[0m, in \u001b[0;36mSwinTransformerBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    289\u001b[0m x_windows \u001b[39m=\u001b[39m x_windows\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size, C)  \u001b[39m# num_win*B, window_size*window_size, C\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[39m# W-MSA/SW-MSA\u001b[39;00m\n\u001b[0;32m--> 292\u001b[0m attn_windows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(x_windows, mask\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn_mask)  \u001b[39m# num_win*B, window_size*window_size, C\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[39m# merge windows\u001b[39;00m\n\u001b[1;32m    295\u001b[0m attn_windows \u001b[39m=\u001b[39m attn_windows\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size, C)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/timm/models/swin_transformer.py:177\u001b[0m, in \u001b[0;36mWindowAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    174\u001b[0m     x \u001b[39m=\u001b[39m attn \u001b[39m@\u001b[39m v\n\u001b[1;32m    176\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mreshape(B_, N, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 177\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproj(x)\n\u001b[1;32m    178\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_drop(x)\n\u001b[1;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(NUM_EPOCHS)):\n",
    "    # # Play games as white or black against the previous best model\n",
    "    # if i % 2 == 0:\n",
    "    #     observations, actions, log_probs, values, done_mask, rewards = play_game(env, model, best_model, perspective=chess.WHITE, sample_n=3)\n",
    "    # else:\n",
    "    #     observations, actions, log_probs, values, done_mask, rewards = play_game(env, best_model, model, perspective=chess.BLACK, sample_n=3)\n",
    "    \n",
    "    # next_values = values[1:] + [0] # Value of next state, 0 for final action\n",
    "\n",
    "    # # Convert data to PyTorch tensors\n",
    "    # # observations = torch.as_tensor(observations, dtype=torch.float32, device=model.device)\n",
    "    # actions = torch.as_tensor(actions, dtype=torch.int64, device= model.device)\n",
    "    # log_probs = torch.stack(log_probs).to(model.device)\n",
    "    # values = torch.as_tensor(values, dtype=torch.float32, device= model.device)\n",
    "    # rewards = torch.as_tensor(rewards, dtype=torch.float32, device= model.device)\n",
    "    # next_values = torch.as_tensor(next_values, dtype=torch.float32, device= model.device)\n",
    "    # done_mask = torch.as_tensor(done_mask, dtype=torch.float32, device= model.device)\n",
    "\n",
    "    # model.update_network(log_probs, rewards, values, next_values, done_mask, gamma=0.99)\n",
    "\n",
    "    # # # Expert Study\n",
    "    # # # if i % STUDY_EVERY == 0:\n",
    "    # # if True:\n",
    "    # #     expert_study(model, chess_dataset, percent_dataset=0.05)\n",
    "\n",
    "    # Darwinian duel to the death\n",
    "    if i % DUEL_EVERY == 0:\n",
    "        win_ratio = duel(env, best_model, model, num_rounds=10)\n",
    "        print(f\"Model win ratio: {win_ratio}\")\n",
    "        if win_ratio > 0.6:\n",
    "            print(\"Best model was deafeted!\")\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(model.state_dict(), MODEL_SAVEPATH)\n",
    "            best_model.eval()\n",
    "\n",
    "    # Self play\n",
    "    observations, actions, log_probs, values, done_mask, rewards = play_game(env, model, model, perspective=None, sample_n=3)\n",
    "    next_values = values[1:] + [0] # Value of next state, 0 for final action\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    # observations = torch.as_tensor(observations, dtype=torch.float32, device=model.device)\n",
    "    actions = torch.as_tensor(actions, dtype=torch.int64, device= model.device)\n",
    "    log_probs = torch.stack(log_probs).to(model.device)\n",
    "    values = torch.as_tensor(values, dtype=torch.float32, device= model.device)\n",
    "    rewards = torch.as_tensor(rewards, dtype=torch.float32, device= model.device)\n",
    "    next_values = torch.as_tensor(next_values, dtype=torch.float32, device= model.device)\n",
    "    done_mask = torch.as_tensor(done_mask, dtype=torch.float32, device= model.device)\n",
    "\n",
    "    model.update_network(log_probs, rewards, values, next_values, done_mask, gamma=0.99, selfplay=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
